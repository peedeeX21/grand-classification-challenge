{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand Classification Challenge\n",
    "by Felix MÃ¼ller & Peter Schrott\n",
    "\n",
    "The file digits.zip provided contains training and test images of handwritten digits. Each row describes one of the 28x28 pixel sample-images (see a few examples below). The dataset is split in two parts, 500 examples in the training set and 500 examples in the test set. For the training set, the first number represents the target class (i.e. 0-9). For the testset, these assignments are random and can be ignored. The remaining numbers define the image in a sparse representation, i.e., by giving pairs of PixelID:GrayValue where black pixels (GrayValue=0) are not explicitly listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the modules\n",
    "import numpy as np\n",
    "from sidekit.libsvm import svmutil\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.ndimage import interpolation\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Inspect the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset using `libsvm` and convert the sparse feature vectors to ndarray. The colors of the digits are inverted, i.e. white strokes on black backgorund. Hence filling up the feature vectors with `0` values for the black background values.\n",
    "\n",
    "The values of the resulting feature vectors are inverted after. This is mainly for visualisation purpouse and does not bring any advantages during classification of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def convert_to_ndarray(X_in, n_dim=28*28):\n",
    "    '''\n",
    "    Synopsis:\n",
    "        X = convert_to_ndarray(X_raw)\n",
    "    Arguments:\n",
    "        X_raw:   list o tuples (pixelID:GreyValue) in a dict of samples \n",
    "    Output:\n",
    "        X:       2D array of non-sparese features (samples x features)\n",
    "    '''\n",
    "    X_out = np.zeros((len(X_in), n_dim))\n",
    "    for i, xi in enumerate(X_in):\n",
    "        key_list = list(X_in[i].keys())\n",
    "        value_list = list(X_in[i].values())\n",
    "        X_out[i,key_list] = value_list\n",
    "    return X_out\n",
    "\n",
    "def invert_pixels(X_in):\n",
    "    '''\n",
    "    Invert the colors (white strokes -> black strokes).\n",
    "    \n",
    "    Synopsis:\n",
    "        X = invert_pixels(X_in)\n",
    "    Arguments:\n",
    "        X_in:   2D array samples (samples x features) \n",
    "    Output:\n",
    "        X:      2D array of non-sparese features (samples x features)\n",
    "    '''\n",
    "    X_out = (np.ones(X_in.shape) * 255) - X_in\n",
    "    return X_out\n",
    "\n",
    "def plot_examples(X, y, title):\n",
    "    '''\n",
    "    Plots the frist 12 images of the given data set and their labels.\n",
    "    \n",
    "    Synopsis:\n",
    "        plot_examples(X, y)\n",
    "    Arguments:\n",
    "        X:   2D array samples (samples x features) \n",
    "        y:   Vector of labels\n",
    "    '''\n",
    "    fig = plt.figure(1, figsize=(6*2, 2*2+1))\n",
    "    plt.suptitle(title)\n",
    "    for i in range(12):\n",
    "        ax = fig.add_subplot(2,6,i+1)\n",
    "        ax.imshow(X[i,:].reshape(28, 28), cmap=plt.cm.gray, interpolation = \"none\")\n",
    "        ax.set_title('label: {:d}'.format(y[i]))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_raw, X_raw = svmutil.svm_read_problem('../data/digits/digit_train')\n",
    "_, X_validation_raw = svmutil.svm_read_problem('../data/digits/digit_test')\n",
    "\n",
    "X = convert_to_ndarray(X_raw)\n",
    "X = invert_pixels(X)\n",
    "y = np.asarray(y_raw).astype(int)\n",
    "X_validation = convert_to_ndarray(X_validation_raw)\n",
    "X_validation = invert_pixels(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the 12 first trainings images alongside their labels. Its a good first impression how the data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_examples(X, y, 'Original Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More investigation on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize in 2D\n",
    "Using PCA to determine the 2 principal components and embedd the trainings data in the reduced 2-dimensional space. A very blurry clustering can already be seen. This is an indication for the separability of the digit classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_embedded = pca.transform(X)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for d in range(10):\n",
    "    plt.scatter(X_embedded[y==d,0], X_embedded[y==d,1], s=14, label=d)\n",
    "plt.clim(0,9)\n",
    "plt.title(\"original test set embedded in 2 dimensions\")\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The principal components spectrum\n",
    "\n",
    "The spectrum of the principal components shows the percentage of the variance which is explained by a principal components. This analysis is helpful when it comes to choosing the number of principal components to embed the data in. One can see that 90% of the variance is explained by around the first 60 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "explained_variance_ratio_cum = explained_variance_ratio.cumsum()\n",
    "x_90 = next(x[0] for x in enumerate(explained_variance_ratio_cum) if x[1] > 0.9)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.plot(explained_variance_ratio)\n",
    "ax1.set_xlabel('# principal component')\n",
    "ax1.set_ylabel('explained variance [%]')\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.plot(explained_variance_ratio_cum)\n",
    "ax2.axhline(0.9, c='red', label='90%')\n",
    "ax2.axvline(x_90, c='green', label='{:d} PCs'.format(x_90))\n",
    "ax2.set_xlabel('# principal component')\n",
    "ax2.set_ylabel('cumulated explained variance [%]')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand the dataset\n",
    "\n",
    "Due to the fact that the dataset was reduced for the callenge, we extend the number of samples artificially. Only 500 samles where given to train the classifyer. With the extention of the dataset we expect a better generalization of the model which leads to a better out of sample prediction on the provided validation dataset. This prediciton is used to assess the model by the authorities. \n",
    "\n",
    "Two apporaces are choosen to expand the dataset:\n",
    "1. Rotate the digits within every picture. This feels somehow natrual as the tilt of handwritten digits among people differs.\n",
    "2. Shift the digits by some pixels. As it can be seen in the first visualizations, the digits are not always in the very center (compare the two 7s).\n",
    "\n",
    "Of course one can come up very more sophisticated extentions of the dataset, e.g. zooming or creating artifical digit images based on averages or principal components of one digit class.\n",
    "\n",
    "After the modification of the handwritten image data, we choose to visualize da same images again to get a feeling about the choosen parameter and the resulting outcome. Finally the same visualisation of embedding as above is done. It can bee seen that the clustring is maintained and even gets more dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def rotate_digits(X_in, angle):\n",
    "    '''\n",
    "    Rotates every digit image by the given angle.\n",
    "    \n",
    "    Synopsis:\n",
    "        X_rot = rotate_digits(X, 10)\n",
    "    Arguments:\n",
    "        X:       2D array samples (samples x features) \n",
    "        angle:   The rotation angle\n",
    "    '''\n",
    "    X_out = np.empty(X_in.shape)\n",
    "    for i, x_i in enumerate(X_in):\n",
    "        x_i = x_i.reshape(28, 28)\n",
    "        x_i_rotated = interpolation.rotate(x_i, angle=angle, cval=255)\n",
    "        start_idx = int((x_i_rotated.shape[0]-28)/2)\n",
    "        end_idx = start_idx + 28\n",
    "        x_i_rotated = x_i_rotated[start_idx:end_idx,start_idx:end_idx]\n",
    "        x_i_rotated[x_i_rotated > 250] = 255\n",
    "        x_i_rotated[x_i_rotated < 5] = 0\n",
    "        X_out[i, :] = x_i_rotated.reshape(1, 28*28)\n",
    "    return X_out\n",
    "\n",
    "def shift_digits(X_in, n_pixel_x, n_pixel_y):\n",
    "    '''\n",
    "    Shifts every digit image by the given number of pixel in according direction.\n",
    "    \n",
    "    Synopsis:\n",
    "        X_shift = shift_digits(X, 0, 2)\n",
    "    Arguments:\n",
    "        X:           2D array samples (samples x features) \n",
    "        n_pixel_x:   number of pixels in x direction\n",
    "        n_pixel_y:   number of pixels in y direction\n",
    "    '''\n",
    "    X_out = np.empty(X_in.shape)\n",
    "    for i, x_i in enumerate(X_in):\n",
    "        x_i = x_i.reshape(28, 28)\n",
    "        x_i_shift = interpolation.shift(x_i, shift=[-n_pixel_y, n_pixel_x], cval=255)\n",
    "        X_out[i, :] = x_i_shift.reshape(1, 28*28)\n",
    "    return X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_rot_p = rotate_digits(X, 10)\n",
    "X_rot_n = rotate_digits(X, -10)\n",
    "X_shift_r = shift_digits(X, 2, 0)\n",
    "X_shift_l = shift_digits(X, -2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the modified dataset to get an idea what happend\n",
    "plot_examples(X_rot_p, y, 'Dataset with rotated digits (+10deg)')\n",
    "plot_examples(X_shift_r, y, 'Dataset with shifted digits (2px)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_exp = np.vstack((X_rot_n, X_rot_p, X_shift_l, X_shift_r, X))\n",
    "y_exp = np.tile(y, 5)\n",
    "\n",
    "plot_list = [(X, y, 'original test set embedded in 2 dimensions'), \n",
    "            (X_rot_p, y, 'rotated test set embedded in 2 dimensions'), \n",
    "            (X_shift_r, y, 'shifted test set embedded in 2 dimensions'), \n",
    "            (X_exp, y_exp, 'expaned test set embedded in 2 dimensions')]\n",
    "n_digits = 5\n",
    "\n",
    "fig = plt.figure(figsize=(14, 14))\n",
    "\n",
    "for i, (X_tmp, y_tmp, title) in enumerate(plot_list):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X_tmp)\n",
    "    X_embedded = pca.transform(X_tmp)\n",
    "    ax = fig.add_subplot(2,2,i+1)\n",
    "    for d in range(n_digits):\n",
    "        ax.scatter(X_embedded[y_tmp==d,0], X_embedded[y_tmp==d,1], s=10, label=d)\n",
    "    ax.set_xlabel('PC 1')\n",
    "    ax.set_ylabel('PC 2')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the classification two apporaces are choosen. Primarily use a ensamble of PCA and KNN in a two step approach. First reduce the dimensionality of the dataset with PCA, then perform a classification by K-Nearest-Neighbor algorightm. Secondly Decssion Trees in a Random Forest are trained and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def crossvalidation(clf, X, y, n_folds=8):\n",
    "    score_array = np.empty((n_folds, 1))\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    for ff, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "        # fit the model\n",
    "        clf.fit(X_train, y_train)\n",
    "        # predict and meassure the error\n",
    "        score_array[ff] = clf.score(X_test, y_test)\n",
    "\n",
    "    return np.mean(score_array)\n",
    "\n",
    "def plot_two_params_score(score_array, x, y, xlabel, ylabel, classifier_name):\n",
    "    plt.imshow(score_array.T, interpolation='none')\n",
    "    plt.xticks(np.arange(x.shape[0]), x, rotation='vertical')\n",
    "    plt.yticks(np.arange(y.shape[0]), y)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title('Score of {} [best={:4f}]'.format(classifier_name, score_array.max()))\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with KNN powerd by PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_pc_array = np.array([1,2,3,4,5,10,20,50,100,200,500])\n",
    "n_neighbors_array = np.arange(2, 12, 1)\n",
    "score_array = np.zeros((n_pc_array.shape[0], n_neighbors_array.shape[0]))\n",
    "\n",
    "for i, n_pc in enumerate(n_pc_array):\n",
    "    for j, n_neighbors in enumerate(n_neighbors_array):\n",
    "        pca = PCA(n_components=n_pc, whiten=True)\n",
    "        pca.fit(X_exp)\n",
    "        X_embedded = pca.transform(X_exp)\n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        score_array[i,j] = crossvalidation(knn, X_embedded, y_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1)   \n",
    "fig.set_size_inches((14, 5))\n",
    "plot_two_params_score(score_array, n_pc_array, n_neighbors_array, 'number pc', 'k', 'KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_estimators_array = np.array([10,50,100,200,500,1000])\n",
    "min_samples_leaf_array = np.arange(2, 5, 1)\n",
    "score_array = np.zeros((n_estimators_array.shape[0], min_samples_leaf_array.shape[0]))\n",
    "tuned_parameters = [{\n",
    "    'n_estimators': n_estimators_array, \n",
    "    'min_samples_leaf': min_samples_leaf_array\n",
    "}]\n",
    "rf = RandomForestClassifier(criterion=\"gini\")\n",
    "clf = GridSearchCV(rf, tuned_parameters, cv=8)\n",
    "clf.fit(X_exp, y_exp)\n",
    "score_array = np.asarray(clf.cv_results_['mean_test_score']) \\\n",
    "    .reshape(n_estimators_array.shape[0], min_samples_leaf_array.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1)   \n",
    "fig.set_size_inches((5, 6))\n",
    "plot_two_params_score(score_array, n_estimators_array, min_samples_leaf_array, \n",
    "                      'n estimators', 'min samples leaf', 'Random Forest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
